{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Work in progress] Analyses of the Hofree et al. original datasets\n",
    "You can download the original Matlab code and dataset from the UCSD's [Network Based Stratification](http://chianti.ucsd.edu/~mhofree/wordpress/?page_id=26) webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFolder='data/'\n",
    "data = loadmat(dataFolder+'somatic_data_OV.mat')\n",
    "network = loadmat(dataFolder+'adj_mat.mat')\n",
    "entrez_to_idmat = loadmat(dataFolder+'entrez_to_idmat.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.keys()\n",
    "len(data['gene_id_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mutations=data['gene_indiv_mat']\n",
    "mutations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print network.keys()\n",
    "net=network['adj_mat']\n",
    "net.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entrez_to_idmat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(entrez_to_idmat['keymat'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys=[x[0] for x in entrez_to_idmat['keymat'][0]]\n",
    "ids=[x[0][0] for x in entrez_to_idmat['entrezid'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entrez_to_idmat['keymat'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys[249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids[249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes = [x[0] for x in data['gene_id_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l=[]\n",
    "subnet=[]\n",
    "good=[]\n",
    "bad=[]\n",
    "for j,g in enumerate(genes):\n",
    "    try:\n",
    "        i=ids.index(g)\n",
    "        subnet.append(i)\n",
    "        good.append(j)\n",
    "    except:\n",
    "        i=np.nan\n",
    "        bad.append(j)\n",
    "    l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Global list length:\",len(l)\n",
    "print \"Identified:\",len(good)\n",
    "print \"Unidentified:\",len(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet=net[subnet][:,subnet]\n",
    "nnet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmut=mutations[:,good]\n",
    "nmut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnnet=np.bmat([[np.matrix(nnet.todense()), np.matrix(np.zeros([nnet.shape[0],len(bad)]))], [np.matrix(np.zeros([len(bad),nnet.shape[0]])), np.matrix(np.diagflat(np.zeros(len(bad))))]])\n",
    "nnmut=mutations[:,good+bad]\n",
    "symbols=data['gene_id_symbol'][good+bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Network size:\",nnnet.shape\n",
    "print \"Mutation size:\",nnmut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree=np.squeeze(np.array(nnnet.sum(axis=0)))\n",
    "figure(1,figsize=(16,10))\n",
    "plot(degree)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (degree==0).sum(), \"genes without neighboors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filteredPatients=nnmut.sum(axis=1)<10\n",
    "print \"Removing\",filteredPatients.sum(),\"patients with less than 10 mutations\"\n",
    "nnmutFiltered=nnmut[filteredPatients==False,:]\n",
    "nnmutFiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(1,figsize=(16,10))\n",
    "imshow(nnmutFiltered)\n",
    "set_cmap('Greys')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,10))\n",
    "plot(np.squeeze(np.asarray(nnmutFiltered[1,:])))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutationProfileDiffusion(mutationProfile,PPIAdjacencyMatrix,diffusionFactor):\n",
    "    tmp=np.array(PPIAdjacencyMatrix.sum(axis=0))\n",
    "    tmp[tmp==0]=1\n",
    "    A=PPIAdjacencyMatrix*np.diagflat(1./tmp)\n",
    "    X1=mutationProfile\n",
    "    X2=diffusionFactor*X1*A+(1-diffusionFactor)*mutationProfile\n",
    "    while norm(X2-X1)>10e-6:\n",
    "        X1=X2\n",
    "        X2=diffusionFactor*X1*A+(1-diffusionFactor)*mutationProfile\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnmutDiffused=mutationProfileDiffusion(nnmutFiltered,nnnet,0.8)\n",
    "nnmutDiffused[np.isnan(nnmutDiffused)]=0\n",
    "plt.figure(1,figsize=(16,10))\n",
    "plot(np.squeeze(np.asarray(nnmutDiffused[1,:])))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(1,figsize=(16,10))\n",
    "imshow(nnmutDiffused)\n",
    "set_cmap('Greys')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(1,figsize(16,10))\n",
    "hist(np.array(np.squeeze(nnmutDiffused[:,:6306].reshape((1,-1)))).T, 50, normed=1, histtype='stepfilled')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(1,figsize(16,10))\n",
    "hist(np.array(np.squeeze(nnmutDiffused[:,6307:].reshape((1,-1)))).T, 50, normed=1, histtype='stepfilled')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.from_numpy_matrix(nnnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import ProjectedGradientNMF\n",
    "model = ProjectedGradientNMF(n_components=3, init='random', random_state=0)\n",
    "model.fit(np.matrix(nnmutFiltered))\n",
    "sklearnComp=model.components_\n",
    "sklearnStrat=np.argmax(model.transform(np.matrix(nnmutFiltered)),axis=1)\n",
    "plt.figure(1,figsize=(16,10))\n",
    "plot(sklearnComp.T/sklearnComp.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import ProjectedGradientNMF\n",
    "model = ProjectedGradientNMF(n_components=3, init='random', random_state=0)\n",
    "model.fit(np.matrix(nnmutDiffused))\n",
    "sklearnCompDiff=model.components_\n",
    "sklearnStratDiff=np.argmax(model.transform(np.matrix(nnmutFiltered)),axis=1)\n",
    "plt.figure(1,figsize=(16,10))\n",
    "plot(sklearnCompDiff.T/sklearnComp.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reuse scikit-learn functions\n",
    "import scipy.sparse as sp\n",
    "from sklearn.utils import atleast2d_or_csr, check_random_state, check_arrays\n",
    "from sklearn.utils.extmath import randomized_svd, safe_sparse_dot\n",
    "\n",
    "def check_non_negative(X, whom):\n",
    "    X = X.data if sp.issparse(X) else X\n",
    "    if (X < 0).any():\n",
    "        raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
    "\n",
    "def _sparseness(x):\n",
    "    \"\"\"Hoyer's measure of sparsity for a vector\"\"\"\n",
    "    sqrt_n = np.sqrt(len(x))\n",
    "    return (sqrt_n - np.linalg.norm(x, 1) / norm(x)) / (sqrt_n - 1)\n",
    "\n",
    "def safe_vstack(Xs):\n",
    "    if any(sp.issparse(X) for X in Xs):\n",
    "        return sp.vstack(Xs)\n",
    "    else:\n",
    "        return np.vstack(Xs)\n",
    "\n",
    "def NBS_init(X,n_components,init=None):\n",
    "        n_samples, n_features = X.shape\n",
    "        if init is None:\n",
    "            if n_components < n_features:\n",
    "                init = 'nndsvd'\n",
    "            else:\n",
    "                init = 'random'\n",
    "\n",
    "\n",
    "        if init == 'nndsvd':\n",
    "            W, H = _initialize_nmf(X, n_components)\n",
    "        elif init == \"random\":\n",
    "            rng = check_random_state(random_state)\n",
    "            W = rng.randn(n_samples, n_components)\n",
    "            # we do not write np.abs(W, out=W) to stay compatible with\n",
    "            # numpy 1.5 and earlier where the 'out' keyword is not\n",
    "            # supported as a kwarg on ufuncs\n",
    "            np.abs(W, W)\n",
    "            H = rng.randn(n_components, n_features)\n",
    "            np.abs(H, H)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Invalid init parameter: got %r instead of one of %r' %\n",
    "                (init, (None, 'nndsvd', 'nndsvda', 'nndsvdar', 'random')))\n",
    "        return W, H\n",
    "\n",
    "def _initialize_nmf(X, n_components, variant=None, eps=1e-6,\n",
    "                    random_state=None):\n",
    "    \"\"\"NNDSVD algorithm for NMF initialization.\n",
    "\n",
    "    Computes a good initial guess for the non-negative\n",
    "    rank k matrix approximation for X: X = WH\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    X : array, [n_samples, n_features]\n",
    "        The data matrix to be decomposed.\n",
    "\n",
    "    n_components : array, [n_components, n_features]\n",
    "        The number of components desired in the approximation.\n",
    "\n",
    "    variant : None | 'a' | 'ar'\n",
    "        The variant of the NNDSVD algorithm.\n",
    "        Accepts None, 'a', 'ar'\n",
    "        None: leaves the zero entries as zero\n",
    "        'a': Fills the zero entries with the average of X\n",
    "        'ar': Fills the zero entries with standard normal random variates.\n",
    "        Default: None\n",
    "\n",
    "    eps: float\n",
    "        Truncate all values less then this in output to zero.\n",
    "\n",
    "    random_state : numpy.RandomState | int, optional\n",
    "        The generator used to fill in the zeros, when using variant='ar'\n",
    "        Default: numpy.random\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    (W, H) :\n",
    "        Initial guesses for solving X ~= WH such that\n",
    "        the number of columns in W is n_components.\n",
    "\n",
    "    Remarks\n",
    "    -------\n",
    "\n",
    "    This implements the algorithm described in\n",
    "    C. Boutsidis, E. Gallopoulos: SVD based\n",
    "    initialization: A head start for nonnegative\n",
    "    matrix factorization - Pattern Recognition, 2008\n",
    "\n",
    "    http://tinyurl.com/nndsvd\n",
    "    \"\"\"\n",
    "    check_non_negative(X, \"NMF initialization\")\n",
    "    if variant not in (None, 'a', 'ar'):\n",
    "        raise ValueError(\"Invalid variant name\")\n",
    "\n",
    "    U, S, V = randomized_svd(X, n_components)\n",
    "    W, H = np.zeros(U.shape), np.zeros(V.shape)\n",
    "\n",
    "    # The leading singular triplet is non-negative\n",
    "    # so it can be used as is for initialization.\n",
    "    W[:, 0] = np.sqrt(S[0]) * np.abs(U[:, 0])\n",
    "    H[0, :] = np.sqrt(S[0]) * np.abs(V[0, :])\n",
    "\n",
    "    for j in range(1, n_components):\n",
    "        x, y = U[:, j], V[j, :]\n",
    "\n",
    "        # extract positive and negative parts of column vectors\n",
    "        x_p, y_p = np.maximum(x, 0), np.maximum(y, 0)\n",
    "        x_n, y_n = np.abs(np.minimum(x, 0)), np.abs(np.minimum(y, 0))\n",
    "\n",
    "        # and their norms\n",
    "        x_p_nrm, y_p_nrm = norm(x_p), norm(y_p)\n",
    "        x_n_nrm, y_n_nrm = norm(x_n), norm(y_n)\n",
    "\n",
    "        m_p, m_n = x_p_nrm * y_p_nrm, x_n_nrm * y_n_nrm\n",
    "\n",
    "        # choose update\n",
    "        if m_p > m_n:\n",
    "            u = x_p / x_p_nrm\n",
    "            v = y_p / y_p_nrm\n",
    "            sigma = m_p\n",
    "        else:\n",
    "            u = x_n / x_n_nrm\n",
    "            v = y_n / y_n_nrm\n",
    "            sigma = m_n\n",
    "\n",
    "        lbd = np.sqrt(S[j] * sigma)\n",
    "        W[:, j] = lbd * u\n",
    "        H[j, :] = lbd * v\n",
    "\n",
    "    W[W < eps] = 0\n",
    "    H[H < eps] = 0\n",
    "\n",
    "    if variant == \"a\":\n",
    "        avg = X.mean()\n",
    "        W[W == 0] = avg\n",
    "        H[H == 0] = avg\n",
    "    elif variant == \"ar\":\n",
    "        random_state = check_random_state(random_state)\n",
    "        avg = X.mean()\n",
    "        W[W == 0] = abs(avg * random_state.randn(len(W[W == 0])) / 100)\n",
    "        H[H == 0] = abs(avg * random_state.randn(len(H[H == 0])) / 100)\n",
    "\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adapted version of the NMF function to integrate graph-regularization\n",
    "#\n",
    "# See:\n",
    "# https://github.com/luispedro/milk/blob/master/milk/unsupervised/nnmf/lee_seung.py\n",
    "# https://www.researchgate.net/profile/Zhigang_Luo/publication/258350768_Limited-memory_fast_gradient_descent_method_for_graph_regularized_nonnegative_matrix_factorization/links/0c9605282f7f611648000000.pdf\n",
    "\n",
    "def GNMF(X,L,lambd=0,n_components=None,tol=1e-4,max_iter=100,verbose=False):      \n",
    "        X = atleast2d_or_csr(X)\n",
    "        check_non_negative(X, \"NMF.fit\")\n",
    "        n_samples, n_features = X.shape\n",
    "  \n",
    "        if not n_components:\n",
    "            n_components = n_features\n",
    "        else:\n",
    "            n_components = n_components\n",
    "  \n",
    "        #W, H = NBS_init(X,n_components)\n",
    "        W = np.random.normal(0,1,(n_samples,n_components))**2\n",
    "        H = np.random.normal(0,1,(n_components,n_features))**2\n",
    "        \n",
    "        reconstruction_err_ = norm(X - np.dot(W, H))\n",
    "        eps=1e-4#spacing(1) #10e-14\n",
    "        Lp = (abs(L)+L)/2\n",
    "        Lm = (abs(L)-L)/2\n",
    "       \n",
    "        for n_iter in range(1, max_iter + 1):\n",
    "            if verbose:\n",
    "                print \"Iteration =\", n_iter,\"/\",max_iter, \"â€” Error =\", reconstruction_err_,\"/\",tol\n",
    "            \n",
    "            h1=lambd*np.dot(H,Lm)+np.dot(W.T,(X+eps)/(np.dot(W,H)+eps))\n",
    "            h2=lambd*np.dot(H,Lp)+np.dot(W.T,np.ones(shape(X)))\n",
    "            H = multiply(H,(h1+eps)/(h2+eps))\n",
    "            H[H<=0]=eps\n",
    "            H[np.isnan(H)]=eps\n",
    "            \n",
    "            w1=np.dot((X+eps)/(np.dot(W,H)+eps),H.T)\n",
    "            w2=np.dot(np.ones(shape(X)),H.T)\n",
    "            W = multiply(W,(w1+eps)/(w2+eps))\n",
    "            W[H<=0]=eps\n",
    "            W[np.isnan(W)]=eps            \n",
    "            \n",
    "            if not sp.issparse(X):\n",
    "                if reconstruction_err_ > norm(X - np.dot(W, H)):\n",
    "                    H=(1-eps)*H+eps*np.random.normal(0,1,(n_components,n_features))**2\n",
    "                    W=(1-eps)*W+eps*np.random.normal(0,1,(n_samples,n_components))**2\n",
    "                reconstruction_err_ = norm(X - np.dot(W, H))\n",
    "            else:\n",
    "                norm2X = np.sum(X.data ** 2)  # Ok because X is CSR\n",
    "                normWHT = np.trace(np.dot(np.dot(H.T, np.dot(W.T, W)), H))\n",
    "                cross_prod = np.trace(np.dot((X * H.T).T, W))\n",
    "                reconstruction_err_ = sqrt(norm2X + normWHT - 2. * cross_prod)\n",
    "                    \n",
    "            if reconstruction_err_<tol:\n",
    "                warnings.warn(\"Tolerance error reached during fit\")\n",
    "                break\n",
    "            \n",
    "            if numpy.isnan(W).any() or numpy.isnan(H).any():\n",
    "                warnings.warn(\"NaN values at \"+ str(n_iter)+\" Error=\"+str(reconstruction_err_))\n",
    "                break\n",
    "                              \n",
    "            if n_iter == max_iter:\n",
    "                warnings.warn(\"Iteration limit reached during fit\")\n",
    "  \n",
    "        return np.squeeze(np.asarray(W)), np.squeeze(np.asarray(H)), reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W, stratipyCompG, reconstruction_err_ = GNMF(np.matrix(nnmutFiltered),np.matrix(nnnet),0.8,n_components=3,tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,10))\n",
    "plot(stratipyCompG.T/stratipyCompG.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WDiff, stratipyCompGDiff, reconstruction_err_Diff = GNMF(np.matrix(nnmutDiffused),np.matrix(nnnet),0.8,n_components=3,tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,10))\n",
    "plot(stratipyCompGDiff.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df0=pd.DataFrame({'EntrezId':[g[0] for g in data['gene_id_all'][good+bad]],'Genes':[g[0][0] for g in data['gene_id_symbol'][good+bad]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'StartiPyDiff_1':stratipyCompGDiff[0,:].T,'StartiPyDiff_2':stratipyCompGDiff[1,:].T,'StartiPyDiff_3':stratipyCompGDiff[2,:].T,'StratiPyDiff_W':stratipyCompGDiff.sum(axis=0).T,'StratiPyDiff_Comp':np.argmax(stratipyCompGDiff, axis=0).T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({'StartiPy_1':stratipyCompG[0,:].T,'StartiPy_2':stratipyCompG[1,:].T,'StartiPy_3':stratipyCompG[2,:].T,'StratiPy_W':stratipyCompG.sum(axis=0).T,'StratiPy_Comp':np.argmax(stratipyCompG, axis=0).T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3=pd.DataFrame({'NNF_1':sklearnComp[0,:].T,'NNF_2':sklearnComp[1,:].T,'NNF_3':sklearnComp[2,:].T,'NNF_W':sklearnComp.sum(axis=0).T,'NNF_Comp':np.argmax(sklearnComp, axis=0).T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4=pd.DataFrame({'NNFDiff_1':sklearnCompDiff[0,:].T,'NNFDiff_2':sklearnCompDiff[1,:].T,'NNFDiff_3':sklearnCompDiff[2,:].T,'NNFDiff_W':sklearnCompDiff.sum(axis=0).T,'NNFDiff_Comp':np.argmax(sklearnCompDiff, axis=0).T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([df0,df1,df2,df3,df4],axis=1).to_csv('StratificationResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H=nx.from_numpy_matrix(np.matrix(nnnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_edgelist(H, \"Hofree-edgelist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,10))\n",
    "pos=nx.graphviz_layout(H,prog=\"neato\")\n",
    "cn=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_color=array(np.round(stratipyCompGDiff[cn]*100))\n",
    "nx.draw(H,pos,with_labels=False,node_size=50,node_color=node_color,cmap = plt.cm.Blues)\n",
    "cut = 1.05\n",
    "xmax= cut*max(xx for xx,yy in pos.values())\n",
    "ymax= cut*max(yy for xx,yy in pos.values())\n",
    "plt.xlim(0,xmax)\n",
    "plt.ylim(0,ymax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import isfile, join, expanduser\n",
    "mypath=expanduser(\"~/Dropbox/science/Pasteur/Listes Genes/\")\n",
    "SelectedPPI=pd.read_csv(join(mypath,'PPI_150526.csv'))\n",
    "SelectedPPI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G=nx.from_pandas_dataframe(SelectedPPI, 'entrez_gene_ida', 'entrez_gene_idb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G=G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodelist=[g[0] for g in data['gene_id_all'][good+bad]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nnnnet=nx.to_numpy_matrix(G,nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnnmutDiffused=mutationProfileDiffusion(nnmutFiltered,nnnnet,0.8)\n",
    "nnnmutDiffused[np.isnan(nnmutDiffused)]=0\n",
    "plt.figure(1,figsize=(16,10))\n",
    "plot(np.squeeze(np.asarray(nnmutDiffused[1,:])))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Stratification=np.argmax(stratipyCompGDiff,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Weights=np.array([stratipyCompGDiff[i,idx] for idx,i in enumerate(Stratification)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for comp in range(3):\n",
    "    selectedGenes=symbols[((Stratification==comp)*(Weights>0.01))]\n",
    "    print comp+1,len(selectedGenes)\n",
    "    for g in selectedGenes:\n",
    "        print g[0][0]\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err=np.zeros((20,11))\n",
    "for ncomp in range(20):\n",
    "    for smooth in range(11):\n",
    "        print \"Ncomp=\",ncomp+1,\" Smooth=\",smooth/10.,\n",
    "        WDiff2,stratipyCompGDiff2,error = GNMF(np.matrix(nnnmutDiffused),np.matrix(nnnnet),smooth/10.,n_components=ncomp+1,tol=1e-3,max_iter=5)\n",
    "        err[ncomp,smooth]=error\n",
    "        print \" Error=\",error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err2=np.zeros((20,11))\n",
    "for ncomp in range(20):\n",
    "    for smooth in range(11):\n",
    "        print \"Ncomp=\",ncomp+1,\" Smooth=\",smooth/10.,\n",
    "        WDiff2,stratipyCompGDiff2,error = GNMF(np.matrix(nnmutFiltered),np.matrix(nnnnet),smooth/10.,n_components=ncomp+1,tol=1e-3,max_iter=5)\n",
    "        err2[ncomp,smooth]=error\n",
    "        print \" Error=\",error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(20,11))\n",
    "subplot(121)\n",
    "imshow(err, interpolation=\"nearest\")\n",
    "gca().invert_yaxis()\n",
    "xticks(np.arange(11),np.arange(11)/10.)\n",
    "yticks(np.arange(20),np.arange(20)+1)\n",
    "ylabel(\"Number of Component(s)\")\n",
    "xlabel(\"Smoothing factor\")\n",
    "title(\"Absolute error\")\n",
    "colorbar()\n",
    "subplot(122)\n",
    "imshow(err-np.matrix(mean(err,axis=1)).T*np.matrix(np.ones(11)), interpolation=\"nearest\")\n",
    "gca().invert_yaxis()\n",
    "xticks(np.arange(11),np.arange(11)/10.)\n",
    "yticks(np.arange(20),np.arange(20)+1)\n",
    "ylabel(\"Number of Component(s)\")\n",
    "xlabel(\"Smoothing factor\")\n",
    "title(\"Relative error by number of component\")\n",
    "colorbar()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(20,10))\n",
    "subplot(121)\n",
    "imshow(err2, interpolation=\"nearest\")\n",
    "gca().invert_yaxis()\n",
    "xticks(np.arange(11),np.arange(11)/10.)\n",
    "yticks(np.arange(20),np.arange(20)+1)\n",
    "ylabel(\"Number of Component(s)\")\n",
    "xlabel(\"Smoothing factor\")\n",
    "title(\"Absolute error\")\n",
    "colorbar()\n",
    "subplot(122)\n",
    "imshow(err2-np.matrix(mean(err2,axis=1)).T*np.matrix(np.ones(11)), interpolation=\"nearest\")\n",
    "gca().invert_yaxis()\n",
    "xticks(np.arange(11),np.arange(11)/10.)\n",
    "yticks(np.arange(20),np.arange(20)+1)\n",
    "ylabel(\"Number of Component(s)\")\n",
    "xlabel(\"Smoothing factor\")\n",
    "title(\"Relative error by number of component\")\n",
    "colorbar()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Weights=stratipyCompGDiff2.mean(axis=0)\n",
    "hist(Weights,100)\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
